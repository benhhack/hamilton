{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the pandas package - optional\n",
    "# !pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.890006Z",
     "start_time": "2023-09-17T05:43:33.866292Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Add the hamilton module to your path - optinal\n",
    "# project_dir = \"### ADD PATH HERE ###\"\n",
    "# sys.path.append(project_dir)\n",
    "\n",
    "from hamilton import base, driver\n",
    "from hamilton.io.materialization import to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.890336Z",
     "start_time": "2023-09-17T05:43:33.869093Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We use the autoreload extension that comes with ipython to automatically reload modules when\n",
    "# the code in them changes.\n",
    "\n",
    "# import the jupyter extension\n",
    "%load_ext autoreload\n",
    "# set it to only reload the modules imported\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.930823Z",
     "start_time": "2023-09-17T05:43:33.875941Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile spend_calculations.py\n",
    "# Define your new Hamilton functions.\n",
    "# The %%writefile magic command creates a new Python module with the functions below.\n",
    "# We will import this later and pass it into our Driver.\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "# Look at `my_functions` to see how these functions connect.\n",
    "def avg_3wk_spend(spend: pd.Series) -> pd.Series:\n",
    "    \"\"\"Rolling 3 week average spend.\"\"\"\n",
    "    return spend.rolling(3).mean()\n",
    "\n",
    "\n",
    "def spend_per_signup(spend: pd.Series, signups: pd.Series) -> pd.Series:\n",
    "    \"\"\"The cost per signup in relation to spend.\"\"\"\n",
    "    return spend / signups\n",
    "\n",
    "\n",
    "def spend_mean(spend: pd.Series) -> float:\n",
    "    \"\"\"Shows function creating a scalar. In this case it computes the mean of the entire column.\"\"\"\n",
    "    return spend.mean()\n",
    "\n",
    "\n",
    "def spend_zero_mean(spend: pd.Series, spend_mean: float) -> pd.Series:\n",
    "    \"\"\"Shows function that takes a scalar. In this case to zero mean spend.\"\"\"\n",
    "    return spend - spend_mean\n",
    "\n",
    "\n",
    "def spend_std_dev(spend: pd.Series) -> float:\n",
    "    \"\"\"Function that computes the standard deviation of the spend column.\"\"\"\n",
    "    return spend.std()\n",
    "\n",
    "\n",
    "def spend_zero_mean_unit_variance(spend_zero_mean: pd.Series, spend_std_dev: float) -> pd.Series:\n",
    "    \"\"\"Function showing one way to make spend have zero mean and unit variance.\"\"\"\n",
    "    return spend_zero_mean / spend_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.931096Z",
     "start_time": "2023-09-17T05:43:33.881858Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_columns = {  # load from actuals or wherever -- this is our initial data we use as input.\n",
    "    # Note: these values don't have to be all series, they could be a scalar.\n",
    "    \"signups\": pd.Series([1, 10, 50, 100, 200, 400]),\n",
    "    \"spend\": pd.Series([10, 10, 20, 40, 40, 50]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.932468Z",
     "start_time": "2023-09-17T05:43:33.887774Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%aimport spend_calculations\n",
    "\n",
    "df_builder = base.PandasDataFrameResult()\n",
    "dr = driver.Driver({}, spend_calculations)  # can pass in multiple modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.932900Z",
     "start_time": "2023-09-17T05:43:33.892681Z"
    }
   },
   "outputs": [],
   "source": [
    "# we need to specify what we want in the final dataframe. These can be string names, or function references.\n",
    "output_columns = [\n",
    "    \"spend\",\n",
    "    \"signups\",\n",
    "    \"avg_3wk_spend\",\n",
    "    \"spend_per_signup\",\n",
    "    \"spend_zero_mean_unit_variance\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:33.933121Z",
     "start_time": "2023-09-17T05:43:33.896779Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# set up db connection for sql materializer below\n",
    "conn = sqlite3.connect(\"df.db\")\n",
    "\n",
    "# remove an previous instances of the 'test' table that will be created next\n",
    "conn.cursor().execute(\"DROP TABLE IF EXISTS test;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.014270Z",
     "start_time": "2023-09-17T05:43:33.912979Z"
    }
   },
   "outputs": [],
   "source": [
    "materializers = [\n",
    "    # materialize the dataframe to a pickle file\n",
    "    to.pickle(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_pickle\",\n",
    "        path=\"./df.pkl\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    # materialize the dataframe to a JSON file\n",
    "    to.json(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_json\",\n",
    "        filepath_or_buffer=\"./df.json\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    to.sql(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_sql\",\n",
    "        table_name=\"test\",\n",
    "        db_connection=conn,\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    # materialize the dataframe to a XML file\n",
    "    to.xml(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_xml\",\n",
    "        path_or_buffer=\"./df.xml\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    to.html(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_html\",\n",
    "        buf=\"./df.html\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    to.stata(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_stata\",\n",
    "        path=\"./df.dta\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    to.feather(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_feather\",\n",
    "        path=\"./df.feather\",\n",
    "        combine=df_builder,\n",
    "    ),\n",
    "    to.excel(\n",
    "        dependencies=output_columns,\n",
    "        id=\"df_to_excel\",\n",
    "        excel_writer=\"./df.xlsx\",\n",
    "        combine=df_builder\n",
    "    )\n",
    "]\n",
    "# Visualize what is happening\n",
    "dr.visualize_materialization(\n",
    "    *materializers,\n",
    "    additional_vars=output_columns,\n",
    "    inputs=initial_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.026203Z",
     "start_time": "2023-09-17T05:43:34.016610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Materialize a result, i.e. execute the DAG!\n",
    "materialization_results, additional_outputs = dr.materialize(\n",
    "    *materializers,\n",
    "    additional_vars=[\n",
    "        \"df_to_pickle_build_result\",\n",
    "        \"df_to_json_build_result\",\n",
    "        \"df_to_sql_build_result\",\n",
    "        \"df_to_xml_build_result\",\n",
    "        \"df_to_html_build_result\",\n",
    "        \"df_to_stata_build_result\",\n",
    "        \"df_to_feather_build_result\",\n",
    "        \"df_to_excel_build_result\",\n",
    "    ],  # because combine is used, we can get that result here.\n",
    "    inputs=initial_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.041466Z",
     "start_time": "2023-09-17T05:43:34.028346Z"
    }
   },
   "outputs": [],
   "source": [
    "materialization_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.051151Z",
     "start_time": "2023-09-17T05:43:34.043320Z"
    }
   },
   "outputs": [],
   "source": [
    "additional_outputs[\"df_to_pickle_build_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.058608Z",
     "start_time": "2023-09-17T05:43:34.048662Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "additional_outputs[\"df_to_json_build_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.089706Z",
     "start_time": "2023-09-17T05:43:34.060251Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_sql_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_xml_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_html_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_stata_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_feather_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(additional_outputs[\"df_to_excel_build_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T05:43:34.090208Z",
     "start_time": "2023-09-17T05:43:34.066483Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# closing out db connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
